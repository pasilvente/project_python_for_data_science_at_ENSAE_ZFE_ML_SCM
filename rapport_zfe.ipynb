{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82ce2404",
   "metadata": {},
   "source": [
    "# Impact des ZFE sur le NO₂ à Grenoble et Paris  \n",
    "Par Pierre-Andréa Silvente & Paolo Maunas – groupe X\n",
    "\n",
    "<a id=\"introduction\"></a>\n",
    "## Introduction\n",
    "\n",
    "Les zones à faibles émissions (ZFE) sont devenues un instrument central des politiques de lutte contre la pollution atmosphérique dans les grandes agglomérations françaises. Elles reposent sur des restrictions de circulation fondées sur les vignettes Crit’Air, avec pour objectif de réduire les émissions liées au trafic routier, en particulier pour le dioxyde d’azote (NO₂).\n",
    "\n",
    "Mesurer l’effet réel de ces dispositifs n’est cependant pas immédiat. Les concentrations de NO₂ évoluent sous l’effet de nombreux facteurs : tendance de fond liée au renouvellement du parc automobile, conditions météorologiques, réorganisation du trafic, chocs exceptionnels comme la crise sanitaire de 2020, ou encore d’autres politiques publiques environnementales. Une simple comparaison \"avant / après\" l’introduction d’une ZFE ne permet donc pas d’attribuer de façon crédible une éventuelle baisse du NO₂ au seul dispositif.\n",
    "\n",
    "Dans ce projet, nous cherchons à quantifier dans quelle mesure la mise en place des ZFE à Grenoble et à Paris s’est traduite par une diminution des concentrations de NO₂ au niveau de certaines stations urbaines. Pour cela, nous combinons plusieurs jeux de données open data :\n",
    "\n",
    "- des données géographiques décrivant les périmètres de ZFE et leurs dates de mise en œuvre ;\n",
    "- des séries journalières de NO₂ pour des stations situées à l’intérieur des ZFE de Grenoble et de Paris ;\n",
    "- des séries comparables pour des stations d’autres grandes villes françaises, utilisées comme unités \"donneuses\" où cette fois-ci aucune ZFE n'a été mise en place.\n",
    "\n",
    "Nous nous concentrons sur le NO₂ parmi les polluants disponibles sur les plateformes de surveillance (CO, benzène C₆H₆, NOₓ, O₃, SO₂, PM₁₀, etc.), car il s’agit de l’indicateur réglementaire le plus directement lié au trafic routier et celui pour lequel les dépassements des valeurs limites ont motivé la mise en place des ZFE. C’est aussi le polluant pour lequel la couverture spatiale et temporelle des stations est la plus homogène, ce qui facilite les comparaisons entre villes et la construction de contrefactuels.\n",
    "\n",
    "La démarche repose sur trois blocs :\n",
    "\n",
    "1. une analyse descriptive détaillée des niveaux de NO₂ avant et après la mise en place des ZFE, à Grenoble et à Paris, et leur comparaison avec les villes donneuses ;\n",
    "2. un modèle de contrôle synthétique (avec pénalisation Ridge, Lasso et ElasticNet) pour construire, pour chaque station traitée, un contrefactuel \"sans ZFE\" à partir des donneurs ;\n",
    "3. des modèles de machine learning (forêt aléatoire, gradient boosting) utilisés comme contrefactuels alternatifs.\n",
    "\n",
    "L’objectif, ambitieux, est d'étudier la possibilité d'un impact causal des ZFE sur la réduction de NO₂ dans l'atmosphère, tout en proposant une analyse structurée, reproductible et transparente à partir de données publiques, et en mettant en évidence les ordres de grandeur plausibles des effets et les limites de l’approche.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede8777f",
   "metadata": {},
   "source": [
    "## Sommaire\n",
    "\n",
    "- [Installation](#installation)\n",
    "- [Préparation des données](#preparation-des-donnees)\n",
    "  - [Sources et fichiers](#sources-et-fichiers)\n",
    "  - [Données ZFE](#donnees-zfe)\n",
    "  - [Données de pollution à Grenoble](#donnees-grenoble)\n",
    "  - [Données de pollution à Paris](#donnees-paris)\n",
    "  - [Donneurs : sélection des villes et des stations](#donneurs)\n",
    "  - [Construction des séries journalières et mensuelles](#series)\n",
    "  - [Gestion des valeurs manquantes](#valeurs-manquantes)\n",
    "- [Analyse descriptive](#analyse-descriptive)\n",
    "  - [Grenoble : stations Les Frênes et Boulevards](#desc-grenoble)\n",
    "  - [Paris : stations Champs-Élysées et Les Halles](#desc-paris)\n",
    "  - [Comparaison avec les villes donneuses](#desc-donneurs)\n",
    "- [Modélisation par contrôle synthétique](#scm)\n",
    "  - [Principe et mise en œuvre](#scm-principe)\n",
    "  - [Résultats pour Grenoble](#scm-grenoble)\n",
    "  - [Résultats pour Paris](#scm-paris)\n",
    "  - [Effets moyens du traitement (ATT)](#scm-att)\n",
    "- [Modélisation par méthodes de machine learning](#ml)\n",
    "  - [Spécification et stratégie d’estimation](#ml-spec)\n",
    "  - [Résultats pour Grenoble](#ml-grenoble)\n",
    "  - [Résultats pour Paris](#ml-paris)\n",
    "- [Discussion et limites](#discussion)\n",
    "- [Conclusion et perspectives](#conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04f7b0f",
   "metadata": {},
   "source": [
    "<a id=\"installation\"></a>\n",
    "## Installation\n",
    "\n",
    "Ce notebook suppose que le dépôt Git a été cloné en local et que les fichiers de données nettoyés sont disponibles dans le dossier `data/` à la racine du projet.\n",
    "\n",
    "Les fonctions génériques de préparation des données et de modélisation sont regroupées dans des scripts Python du dossier `scripts/` (`data_prep.py`, `scm_models.py`, `ml_models.py`). Le notebook importe ces fonctions au démarrage afin de limiter la duplication de code et de rendre la structure du projet plus lisible.\n",
    "\n",
    "Pour reproduire ce rapport à partir d’un environnement vierge :\n",
    "\n",
    "1. Cloner le dépôt GitHub.  \n",
    "2. Créer un environnement virtuel (optionnel mais recommandé) et l’activer.  \n",
    "3. Installer les dépendances listées dans `requirements.txt` avec `pip install -r requirements.txt`.  \n",
    "4. Exécuter ce notebook depuis le dossier `zfe-scm/`, en veillant à ce que le dossier `data/` et le dossier `scripts/` soient présents à la racine du projet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0111ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Racine du projet : C:\\Users\\Pierre\\Desktop\\Projet Python pour la Data Science\n",
      "Dossier data     : C:\\Users\\Pierre\\Desktop\\Projet Python pour la Data Science\\data\n",
      "Dossier scripts  : C:\\Users\\Pierre\\Desktop\\Projet Python pour la Data Science\\scripts\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "PROJECT_ROOT = Path().resolve()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "SCRIPTS_DIR = PROJECT_ROOT / \"scripts\"\n",
    "\n",
    "print(\"Racine du projet :\", PROJECT_ROOT)\n",
    "print(\"Dossier data     :\", DATA_DIR)\n",
    "print(\"Dossier scripts  :\", SCRIPTS_DIR)\n",
    "\n",
    "if not DATA_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Le dossier data est introuvable : {DATA_DIR}\")\n",
    "\n",
    "if not SCRIPTS_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Le dossier scripts est introuvable : {SCRIPTS_DIR}\")\n",
    "\n",
    "from scripts.data_prep import build_monthly_series, summarize_missing_daily\n",
    "from scripts.scm_models import fit_penalized_scm, compute_att_summary\n",
    "from scripts.zfe_data import build_aires_voies_flat, build_zfe_clean_tables\n",
    "from scripts.build_pollution_data import build_grenoble_no2_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c57ee",
   "metadata": {},
   "source": [
    "<a id=\"preparation-des-donnees\"></a>\n",
    "## Préparation des données\n",
    "\n",
    "<a id=\"adresses\"></a>\n",
    "### 1. Adresses\n",
    "\n",
    "Toutes les données utilisées dans ce projet proviennent de sources ouvertes. Pour assurer la reproductibilité, nous listons ici les principales URL d’origine (portails open data, export ATMO, etc.). Nous utiliserons une copie locale des fichiers bruts le dossier `data/`.\n",
    "\n",
    "Les liens exacts vers les exports utilisés sont renseignés dans les variables ci-dessous. Ils ne sont pas exploités directement dans ce notebook, qui travaille à partir des fichiers bruts, mais ils documentent la provenance des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1c59a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adresses des principales sources de données\n",
    "\n",
    "ZFE_GEOJSON_AIRES_URL = \"https://transport.data.gouv.fr/resources/79567\"\n",
    "ZFE_GEOJSON_VOIES_URL = \"https://transport.data.gouv.fr/resources/79568\"\n",
    "ZFE_IDENTIFIANTS_URL = \"https://transport.data.gouv.fr/resources/79760\"  \n",
    "\n",
    "MESURES_NO2_RAW_URL = \"https://www.geodair.fr/donnees/export-advanced\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5efe2e",
   "metadata": {},
   "source": [
    "<a id=\"donnees-zfe\"></a>\n",
    "### 2. Données ZFE\n",
    "\n",
    "Les périmètres de ZFE utilisés dans ce projet proviennent des fichiers GeoJSON publiés sur data.gouv et sont `aires.geojson` qui décrit les aires sur lesquelles la ZFE s’applique (polygones géographiques) ainsi que `voies.geojson` qui décrit les tronçons de voies concernés.\n",
    "\n",
    "Chaque feature contient deux blocs d’information : un bloc `properties` avec des attributs géographiques et réglementaires et un bloc `publisher` qui décrit la ZFE et la collectivité (identifiant, nom, SIREN, forme juridique, etc.).\n",
    "\n",
    "La table `zfe_ids.csv` également récupérée sur data.gouv fournit des informations supplémentaires par ZFE (SIREN, structure juridique, etc.).\n",
    "\n",
    "Pour rendre ces données exploitables dans le reste du projet, nous avons mis en place le pipeline suivant, implémenté dans le script `scripts/zfe_data.py` :\n",
    "\n",
    "1. **Aplatissement des GeoJSON**  \n",
    "   Les fichiers `aires.geojson` et `voies.geojson` sont lus puis aplatis via la fonction `flatten_geojson`.  \n",
    "   Chaque feature est transformée en une ligne, avec :\n",
    "   - les champs de `properties` ;\n",
    "   - les champs de `publisher` préfixés en `publisher_`.  \n",
    "   Nous obtenons deux tables intermédiaires :\n",
    "   - `aires_flat.csv` ;\n",
    "   - `voies_flat.csv`.\n",
    "\n",
    "2. **Construction de tables nettoyées**  \n",
    "   À partir de ces tables aplaties, nous sélectionnons des colonnes qui pourraient nous être pertinentes pour la suite de notre analyse. Donc : \n",
    "   - pour les aires : identifiant de ZFE, SIREN et nom de la collectivité, dates de début et de fin, informations sur les restrictions par type de véhicule (VP, VUL, poids lourds, bus, deux-roues), liens vers les arrêtés et sites d’information ;\n",
    "   - pour les voies : mêmes informations ZFE/collectivité, plus les identifiants de tronçon (`osm_id`, `ref`, sens de circulation, indicateurs de dérogation, etc.).  \n",
    "   Les dates de début et de fin sont converties au format `datetime`. Enfin, les résultats sont sauvegardés dans deux fichiers csv : `aires_clean.csv` et `voies_clean.csv`.\n",
    "\n",
    "3. **Table de métadonnées `zfe_meta`**  \n",
    "   À partir d’`aires_clean`, nous construisons une table de synthèse avec une ligne par ZFE (`publisher_zfe_id`, `publisher_siren`, `publisher_nom`).  \n",
    "   Pour chaque ZFE, nous agrégons selon le processus suivant :\n",
    "   - la première date de début observée dans les aires (`first_date_debut`) ;\n",
    "   - la dernière date de début (`last_date_debut`) ;\n",
    "   - la première date de fin si une fin est renseignée (`first_date_fin`) ;\n",
    "   - le nombre d’aires couvertes (`n_aires`) ;\n",
    "   - un indicateur de présence d’une restriction VP (`has_vp_restriction`).  \n",
    "\n",
    "   Cette table est ensuite enrichie par jointure avec `zfe_ids.csv` sur le SIREN, afin de récupérer notamment la forme juridique et les informations complémentaires sur la collectivité. Le résultat final est sauvegardé sous le nom `zfe_meta.csv` et sert de table de référence pour identifier les ZFE de Grenoble et de Paris et leurs dates de mise en œuvre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24b522d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aires_flat : (37, 47)\n",
      "voies_flat : (8072, 32)\n",
      "aires_clean : (37, 19)\n",
      "voies_clean : (8072, 24)\n",
      "zfe_meta    : (19, 13)\n",
      "Colonnes de zfe_meta :\n",
      "['publisher_zfe_id', 'publisher_siren', 'publisher_nom', 'first_date_debut', 'last_date_debut', 'first_date_fin', 'n_aires', 'has_vp_restriction', 'siren', 'code', 'epci_principal', 'autres_siren', 'forme_juridique']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher_zfe_id</th>\n",
       "      <th>publisher_siren</th>\n",
       "      <th>publisher_nom</th>\n",
       "      <th>first_date_debut</th>\n",
       "      <th>last_date_debut</th>\n",
       "      <th>first_date_fin</th>\n",
       "      <th>n_aires</th>\n",
       "      <th>has_vp_restriction</th>\n",
       "      <th>siren</th>\n",
       "      <th>code</th>\n",
       "      <th>epci_principal</th>\n",
       "      <th>autres_siren</th>\n",
       "      <th>forme_juridique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANGERS</td>\n",
       "      <td>244900015</td>\n",
       "      <td>CU Angers Loire Métropole</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2026-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>244900015.0</td>\n",
       "      <td>ANGERS</td>\n",
       "      <td>Angers Loire Métropole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Métropole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANNECY</td>\n",
       "      <td>200066793</td>\n",
       "      <td>CA du Grand Annecy</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2030-01-01</td>\n",
       "      <td>2027-12-31</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>200066793.0</td>\n",
       "      <td>ANNECY</td>\n",
       "      <td>Grand Annecy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communauté d'agglomération</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANNEMASSE</td>\n",
       "      <td>200011773</td>\n",
       "      <td>CA Annemasse-Les Voirons-Agglomération</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>200011773.0</td>\n",
       "      <td>ANNEMASSE</td>\n",
       "      <td>Annemasse agglo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communauté d'agglomération</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BORDEAUX</td>\n",
       "      <td>243300316</td>\n",
       "      <td>Bordeaux Métropole</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>243300316.0</td>\n",
       "      <td>BORDEAUX</td>\n",
       "      <td>Bordeaux Métropole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Métropole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CLERMONT-FERRAND</td>\n",
       "      <td>246300701</td>\n",
       "      <td>Clermont Auvergne métropole</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>246300701.0</td>\n",
       "      <td>CLERMONT-FERRAND</td>\n",
       "      <td>Clermont Auvergne métropole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Métropole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publisher_zfe_id  publisher_siren                           publisher_nom  \\\n",
       "0            ANGERS        244900015               CU Angers Loire Métropole   \n",
       "1            ANNECY        200066793                      CA du Grand Annecy   \n",
       "2         ANNEMASSE        200011773  CA Annemasse-Les Voirons-Agglomération   \n",
       "3          BORDEAUX        243300316                      Bordeaux Métropole   \n",
       "4  CLERMONT-FERRAND        246300701             Clermont Auvergne métropole   \n",
       "\n",
       "  first_date_debut last_date_debut first_date_fin  n_aires  \\\n",
       "0       2025-01-01      2025-01-01     2026-12-31        1   \n",
       "1       2025-01-01      2030-01-01     2027-12-31        4   \n",
       "2       2025-01-01      2025-01-01            NaT        1   \n",
       "3       2025-01-01      2025-01-01            NaT        1   \n",
       "4       2023-07-01      2023-07-01            NaT        1   \n",
       "\n",
       "   has_vp_restriction        siren              code  \\\n",
       "0                True  244900015.0            ANGERS   \n",
       "1                True  200066793.0            ANNECY   \n",
       "2                True  200011773.0         ANNEMASSE   \n",
       "3                True  243300316.0          BORDEAUX   \n",
       "4               False  246300701.0  CLERMONT-FERRAND   \n",
       "\n",
       "                epci_principal  autres_siren             forme_juridique  \n",
       "0       Angers Loire Métropole           NaN                   Métropole  \n",
       "1                 Grand Annecy           NaN  Communauté d'agglomération  \n",
       "2              Annemasse agglo           NaN  Communauté d'agglomération  \n",
       "3           Bordeaux Métropole           NaN                   Métropole  \n",
       "4  Clermont Auvergne métropole           NaN                   Métropole  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construction (ou reconstruction) de aires_flat et voies_flat à partir des GeoJSON\n",
    "aires_flat, voies_flat = build_aires_voies_flat(\n",
    "    data_dir=DATA_DIR,\n",
    "    aires_geojson_name=\"aires.geojson\",\n",
    "    voies_geojson_name=\"voies.geojson\",\n",
    "    aires_flat_name=\"aires_flat.csv\",\n",
    "    voies_flat_name=\"voies_flat.csv\",\n",
    ")\n",
    "\n",
    "print(\"aires_flat :\", aires_flat.shape)\n",
    "print(\"voies_flat :\", voies_flat.shape)\n",
    "\n",
    "# Construction des tables nettoyées et de zfe_meta\n",
    "aires_clean, voies_clean, zfe_meta = build_zfe_clean_tables(\n",
    "    data_dir=DATA_DIR,\n",
    "    aires_flat_name=\"aires_flat.csv\",\n",
    "    voies_flat_name=\"voies_flat.csv\",\n",
    "    zfe_ids_name=\"zfe_ids.csv\",\n",
    "    aires_clean_name=\"aires_clean.csv\",\n",
    "    voies_clean_name=\"voies_clean.csv\",\n",
    "    zfe_meta_name=\"zfe_meta.csv\",\n",
    ")\n",
    "\n",
    "print(\"aires_clean :\", aires_clean.shape)\n",
    "print(\"voies_clean :\", voies_clean.shape)\n",
    "print(\"zfe_meta    :\", zfe_meta.shape)\n",
    "print(\"Colonnes de zfe_meta :\")\n",
    "print(list(zfe_meta.columns))\n",
    "\n",
    "zfe_meta.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dba7fe",
   "metadata": {},
   "source": [
    "<a id=\"donnees-grenoble\"></a>\n",
    "### 3. Données de pollution à Grenoble\n",
    "\n",
    "Pour Grenoble, nous utilisons un export brut fourni par ATMO Auvergne–Rhône-Alpes, couvrant plusieurs stations et polluants sur la période 2016–2024. Le fichier brut contient notamment : une colonne d’horodatage (`Date de début`), le nom et le code de la station, le type d’implantation (urbaine, trafic, fond, etc.), le type d’influence, les concentrations par polluant, dont le NO₂ et les coordonnées géographiques de la station (latitude, longitude).\n",
    "\n",
    "Le traitement de cet export est implémenté dans la fonction `build_grenoble_no2_data` du module `scripts/build_pollution_data.py`. Cette fonction procède comme suit. Tout d'abord, elle lit le fichier brut et isole le polluant NO₂, puis construit un jeu de données journalier avec les colonnes `date`, `station_id`, `station_name`, `station_env`, `station_influence`, `no2_ug_m3`, `lat`, `lon`. Ensuite, elle agrège les informations de localisation par station pour construire une table de métadonnées `no2_stations_meta.csv` (une ligne par station). Puis, elle charge la géométrie de la ZFE Grenoble depuis `aires.geojson`, et détermine pour chaque station si elle est située ou non dans le périmètre de la ZFE. Enfin, elle sauvegarde `no2_all_stations_daily_clean.csv` (toutes les stations de l’export), `no2_stations_meta.csv` (métadonnées des stations, avec la colonne `in_zfe_grenoble`) et `pollution_grenoble_no2_daily_clean.csv` (restriction aux stations situées dans la ZFE, utilisées pour la suite de l’analyse).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
